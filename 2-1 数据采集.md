[TOC]

# 数据采集

数据采集主要是分两个模块：业务数据和用户日志数据

主要分为实时增量和历史全量，实时增量的用户日志数据通过flume采集到kafka，实时增量的业务数据通过maxwell同步到kafka，让Flink在线处理；历史全量数据通过datax同步到HDFS，让SparkSQL离线处理

## 1.用户日志数据

### 1.1来源

用户日志数据来源于自己编写的日志数据模拟器生成，通过flume配置kafka channel 实时增量采集到kafka的ods_base_log主题里，准备后续Flink的计算。

### 1.2配置

- 1.将application.yml、app_log.jar、path.json、logback.xml上传到Flink01的opt/module/data目录下

  ```shell
  mkdir /opt/module/data
  ```

上传文件到/opt/module/data目录

- 2.修改配置文件application.yml，可以根据需求生成对应日期的用户行为日志

  ```yaml
  # 外部配置打开
  logging.config: "./logback.xml"
  #业务日期  注意：并不是Linux系统生成日志的日期，而是生成数据中的时间
  mock.date: "2022-12-04"(这里可以根据需求进行修改)
  #模拟数据发送模式
  #mock.type: "http"
  #mock.type: "kafka"
  mock.type: "log"
  
  #http模式下，发送的地址
  mock.url: "http://localhost:8090/app_log"
  
  #kafka模式下，发送的地址
  mock:
    kafka-server: "Flink01:9092,Flink02:9092,Flink03:9092"
    kafka-topic: "ods_base_log"
  
  #启动次数
  mock.startup.count: 200
  #设备最大值
  mock.max.mid: 500000
  #会员最大值
  mock.max.uid: 100
  #商品最大值
  mock.max.sku-id: 35
  #页面平均访问时间
  mock.page.during-time-ms: 20000
  #错误概率 百分比
  mock.error.rate: 3
  #每条日志发送延迟 ms
  mock.log.sleep: 10
  #商品详情来源  用户查询，商品推广，智能推荐, 促销活动
  mock.detail.source-type-rate: "40:25:15:20"
  #领取购物券概率
  mock.if_get_coupon_rate: 75
  #购物券最大id
  mock.max.coupon-id: 3
  #搜索关键词  
  mock.search.keyword: "图书,小米,iphone11,电视,口红,ps5,苹果手机,小米盒子"
  ```

- 3.修改logback文件

  修改日志数据生成的路径，生成的日志文件格式：app.yyyy-MM-dd.log

  ```shell
  <property name="LOG_HOME" value="/opt/module/data/log" />
  ```

- 4.用户日志数据模拟已写成脚本

  ```shell
  app_log.sh(直接运行脚本即可,会生成一批数据文件到data/log/目录下)
  ```

## 2.业务数据

### 2.1来源

业务数据来源于数据模拟器,模拟器会实时向数据库中更新,插入数据,模拟实时增量场景，maxwell实时抓取Mysql的binlog同步到kafka的ods_base_db主题里，准备后续计算。

### 2.2配置

业务数据存在MySQL里，将 模拟数据\业务数据的gmall.sql用工具在MySQL数据库里执行，将表创建好

- 1.在Flink01的/opt/module目录下创建data目录

- 2.将\模拟数据\业务数据的文件上传到目录下

- 3.根据需求修改application.properties配置

  ```shell
  spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
  spring.datasource.url=jdbc:mysql://Flink02:3306/gmall?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=GMT%2B8
  spring.datasource.username=root
  spring.datasource.password=123456
  logging.pattern.console=%m%n
  mybatis-plus.global-config.db-config.field-strategy=not_null
  
  #业务日期
  mock.date=2022-12-04(这里可以根据需求进行更改,如果你想明显得验证得话可以改成当日时间)
  #是否重置  注意：第一次执行必须设置为1，后续不需要重置不用设置为1
  mock.clear=1
  #是否重置用户 注意：第一次执行必须设置为1，后续不需要重置不用设置为1
  mock.clear.user=1
  ```

- 4.在db_log目录下执行命令，生成2022-12-04日的业务数据

  ```shell
  java -jar db_log.jar
  ```

- 5.查看mysq数据库，是否有2022-12-04日的业务数据

## 3.采集用户日志数据

## 4.采集业务数据

## 5.注意事项

/opt/module/data/application.properties

 /opt/module/data/application.yml

/opt/module/maxwell/config.properties

这三个文件里的mock_data应该都是一致，你想模拟哪一天的数据就写哪一天，对于增量而言，日期比较的重要，对于全量而言，模拟的日期就不是很重要，反正是全量同步，当前包括历史的
